# app.py
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.prompts.chat import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    SystemMessagePromptTemplate
)
import os

# Streamlit Community Cloudã®ã€ŒSecretsã€ã‹ã‚‰OpenAI API keyã‚’å–å¾—
# ğŸ”¥ã“ã“ã‚’ä¿®æ­£ï¼ˆç’°å¢ƒå¤‰æ•°ã«ã‚»ãƒƒãƒˆã¯ä¸è¦ï¼ç›´æ¥ä½¿ã†ï¼‰
openai_api_key = st.secrets["OPENAI_API_KEY"]

chat = ChatOpenAI(
    model="gpt-3.5-turbo",
    openai_api_key=openai_api_key   # ğŸ”¥ã“ã“ã«ç›´æ¥ã‚­ãƒ¼ã‚’æ¸¡ã™
)

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
system_template = (
    "ã‚ãªãŸã¯ã€{source_lang} ã‚’ {target_lang}ã«ç¿»è¨³ã™ã‚‹å„ªç§€ãªç¿»è¨³ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç¿»è¨³çµæœä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"
)
system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)
human_template = "{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages(
    [system_message_prompt, human_message_prompt]
)

if "response" not in st.session_state:
    st.session_state["response"] = ""

# LLMã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹é–¢æ•°
def communicate():
    text = st.session_state["user_input"]
    response = chat(
        chat_prompt.format_prompt(
            source_lang=source_lang, target_lang=target_lang, text=text
        ).to_messages()
    )
    st.session_state["response"] = response.content

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã®æ§‹ç¯‰
st.title("ç¿»è¨³ã‚¢ãƒ—ãƒª")
st.write("LangChainã‚’ä½¿ã£ãŸç¿»è¨³ã‚¢ãƒ—ãƒªã§ã™ã€‚")

options = ["æ—¥æœ¬èª", "è‹±èª", "ã‚¹ãƒšã‚¤ãƒ³èª", "ãƒ‰ã‚¤ãƒ„èª", "ãƒ•ãƒ©ãƒ³ã‚¹èª", "ä¸­å›½èª"]
source_lang = st.selectbox(label="ç¿»è¨³å…ƒ", options=options)
target_lang = st.selectbox(label="ç¿»è¨³å…ˆ", options=options)
st.text_input("ç¿»è¨³ã™ã‚‹æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", key="user_input")
st.button("ç¿»è¨³", type="primary", on_click=communicate)

if st.session_state["user_input"] != "":
    st.write("ç¿»è¨³çµæœ:")
    st.write(st.session_state["response"])
